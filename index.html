<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IIT Delhi AI Safety Initiative</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: Arial, sans-serif;
        }

        body {
            line-height: 1.6;
            color: #333;
            background-color: #f9f9f9;
        }

        /* Header */
        header {
            background-color: #003087;
            color: white;
            padding: 2rem;
            text-align: center;
        }

        header h1 {
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }

        header p {
            font-size: 1.2rem;
            opacity: 0.9;
        }

        /* Navigation */
        nav {
            background-color: #004aad;
            padding: 1rem;
        }

        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
            gap: 2rem;
        }

        nav a {
            color: white;
            text-decoration: none;
            font-weight: bold;
        }

        nav a:hover {
            text-decoration: underline;
        }

        /* Main Content */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        section {
            margin-bottom: 3rem;
        }

        section h2 {
            color: #003087;
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        section p {
            font-size: 1.1rem;
            color: #555;
        }

        .cta-button {
            display: inline-block;
            background-color: #5dc1da;
            color: white;
            padding: 0.8rem 1.5rem;
            text-decoration: none;
            border-radius: 5px;
            margin-top: 1rem;
            font-weight: bold;
        }

        .cta-button:hover {
            background-color: #5dc1da;
        }

        /* Footer */
        footer {
            background-color: #003087;
            color: white;
            text-align: center;
            padding: 1rem;
            position: relative;
            bottom: 0;
            width: 100%;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            nav ul {
                flex-direction: column;
                gap: 1rem;
            }

            header h1 {
                font-size: 2rem;
            }

            section h2 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>

<body>
    <header>
        <h1>IIT Delhi AI Safety Initiative</h1>
        <p>Making AI Safe and Reliable</p>
    </header>

    <nav>
        <ul>
            <li><a href="#tov">Our Theory of Victory</a></li>
            <li><a href="#programmes">Programmes</a></li>
            <li><a href="#team">Team</a></li>
            <li><a href="#contact">Contact</a></li>
        </ul>
    </nav>

    <div class="container">
        <section id="about">
            <h2>About Us</h2>
            <p>We are a team of engineering students and researchers dedicated to making AI safe and reliable.</p>
        </section>

        <section id="tov">
            <h2>Our Theory of Victory</h2>
            <p>

                AI safety is a relevant and emerging field that will have enormous consequences in the long term. AI
                researchers hypothesize that AGI will likely be developed within the next three to five years (See <a
                    href="https://www.alignmentforum.org/posts/bb5Tnjdrptu89rcyY/what-s-the-short-timeline-plan">[2]</a>,
                <a href="https://www.alignmentforum.org/posts/K2D45BNxnZjdpSX2j/ai-timelines">[3]</a>) given the current
                rate of progress in AI research and development.

                There are grave consequences in deploying rogue or misaligned AI systems in public, translating to
                monetary losses of millions or billions (See <a
                    href="https://www.calvin-risk.com/blog/decoding-the-monetary-impact">[1]</a>).

            </p>
            <br>
            <p>
                Despite spectacular progress in building new AI systems (See <a
                    href="https://arcprize.org/blog/oai-o3-pub-breakthrough">[7]</a>), there is a glaring stagnation in
                the research and development of safeguards and safety protocols around these systems. According to an
                80000-hour article, there were only around 300 AI safety researchers in 2022 (See <a
                    href="https://80000hours.org/career-reviews/ai-safety-researcher/#:~:text=We%20estimated%20in%202022%20that,risk%20could%20be%20quite%20challenging.">[5]</a>).

                The number of AI safety researchers has been increasing at about 28% per year (See <a
                    href="https://www.lesswrong.com/posts/mC3oeq62DWeqxiNBx/estimating-the-current-and-future-number-of-ai-safety">[6]</a>).
                Using this growth rate, one estimate suggests that the number of AI safety researchers could have
                increased to around 580 by 2024.

                There has been a rise of 315% in AI safety-related articles between 2017 and 2022 (See <a
                    href="https://almanac.eto.tech/topics/ai-safety/#vital-signs">[4]</a> ). However, it is still a
                “drop in the bucket,” with merely 2% of all articles in AI/ML being directly related to safety.

            </p>

            <br>
            <p>
                <strong>
                    What events have to take place starting today to prevent AGI from becoming a catastrophic risk to
                    humanity and/or to mitigate the loss of monetary and human life in the near and long-term future?
                </strong>
            </p>

            <br>
            <p>
                We believe that our best shot at mitigating the risks of AGI is to develop safety and control protocols
                on a technical level and devise new policies for containing potential misuse. Given the dearth of AI
                safety researchers and the proven track record of IITians, this is the most opportune time for
                short-term investment to promote technical AI safety as a career option for IITians and to initiate them
                on this path.

            </p>
            <br>
            <p>
                There are 23 IITs in India, but no AI safety group exists in any of them. The IIT Delhi AI Safety
                Initiative is the first-of-its-kind student research group catering to the bright young minds in
                the Indian subcontinent, modeled around student safety groups at other universities in the West such as
                HAIST <a href="https://haist.ai/">[9]</a>, Oxford AI safety initiative <a
                    href="https://oaisi.org/">[10]</a>, and Berkeley AI safety initiative <a
                    href="https://berkeleyaisafety.com/">[11]</a>.

            </p>
        </section>

        <section id="programmes">
            <h2>Our Programmes</h2>
            <p>
                <li>Weekly Reading Group</li>
                <li>AI Safety Fundamentals Course (Coming Soon)</li>
                <li>Weekly Research Hackathons (Coming Soon)</li>
                <li>Guest Lectures and Seminars (Coming Soon)</li>
            </p>
        </section>

        <section id="team">
            <h2>Our Team</h2>
            <p>
                <li>Basil Labib (<a href="https://basil08.github.io/">Website</a>)</li>
                <li>Gargi Rathi</li>
                <li>Shikhar Gupta</li>
                <li>Manoj Kumar Gorle</li>
            </p>
        </section>

        <section id="contact">
            <h2>Contact Us</h2>
            <p>We are a team of researchers and engineers dedicated to making AI safe and reliable. If you have any
                questions or would like to get in touch, please send us an email to iitdelhi DOT aisi AT gmail DOT
                com.</p>
        </section>
    </div>


    <p><em>Last updated: 2025-04-07</em></p>

    <footer>
        <p>&copy; 2025 IIT Delhi AI Safety Initiative. All rights reserved.</p>
    </footer>

    <script>
        // Minimal JS for smooth scrolling
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
    </script>
</body>

</html>