<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theory of Victory - IIT Delhi AI Safety Initiative</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: Arial, sans-serif;
        }

        body {
            line-height: 1.6;
            color: #333;
            background-color: #f9f9f9;
        }

        /* Header */
        header {
            background-color: #003087;
            color: white;
            padding: 6rem 2rem;
            text-align: center;
            position: relative;
            overflow: hidden;
            margin-top: 4rem;
        }

        header h1 {
            font-size: 4rem;
            margin-bottom: 1rem;
            font-weight: 800;
            line-height: 1.2;
        }

        header p {
            font-size: 1.5rem;
            opacity: 0.9;
            max-width: 800px;
            margin: 0 auto;
        }

        /* Navigation */
        nav {
            background-color: rgba(0, 48, 135, 0.95);
            padding: 1rem 2rem;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            backdrop-filter: blur(10px);
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }

        nav ul {
            list-style: none;
            display: flex;
            justify-content: center;
            gap: 3rem;
            max-width: 1200px;
            margin: 0 auto;
        }

        nav a {
            color: white;
            text-decoration: none;
            font-weight: 500;
            font-size: 1.1rem;
            padding: 0.5rem 0;
            position: relative;
            transition: color 0.3s ease;
        }

        nav a:hover {
            color: #5dc1da;
        }

        nav a::after {
            content: '';
            position: absolute;
            width: 0;
            height: 2px;
            bottom: 0;
            left: 0;
            background-color: #5dc1da;
            transition: width 0.3s ease;
        }

        nav a:hover::after {
            width: 100%;
        }

        /* Main Content */
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 2rem;
        }

        section {
            margin-bottom: 3rem;
            opacity: 0;
            transform: translateY(20px);
            transition: opacity 0.6s ease-out, transform 0.6s ease-out;
        }

        section.visible {
            opacity: 1;
            transform: translateY(0);
        }

        section h2 {
            color: #003087;
            font-size: 2rem;
            margin-bottom: 1rem;
        }

        section p {
            font-size: 1.1rem;
            color: #555;
            margin-bottom: 1.5rem;
        }

        section a {
            color: #5dc1da;
            text-decoration: none;
        }

        section a:hover {
            text-decoration: underline;
        }

        section strong {
            color: #003087;
        }

        /* Footer */
        footer {
            background-color: #003087;
            color: white;
            text-align: center;
            padding: 1rem;
            position: relative;
            bottom: 0;
            width: 100%;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            nav {
                padding: 1rem;
            }

            nav ul {
                flex-direction: column;
                gap: 1rem;
                align-items: center;
            }

            header {
                margin-top: 8rem;
            }

            header h1 {
                font-size: 2rem;
            }

            section h2 {
                font-size: 1.5rem;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1><a href="index.html" style="color: white; text-decoration: none;">IIT Delhi<br>AI Safety Initiative</a></h1>
        <p>We are a team of engineering students and researchers dedicated to making AI safe and reliable.</p>
    </header>

    <nav>
        <ul>
            <li><a href="tov.html">Theory of Victory</a></li>
            <li><a href="team.html">Team</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="resources.html">Resources</a></li>
            <li><a href="contact.html">Contact</a></li>
        </ul>
    </nav>

    <div class="container">
        <section>
            <h2>Our Theory of Victory</h2>
            <p>
                AI safety is a relevant and emerging field that will have enormous consequences in the long term. AI
                researchers hypothesize that AGI will likely be developed within the next three to five years (See <a
                    href="https://www.alignmentforum.org/posts/bb5Tnjdrptu89rcyY/what-s-the-short-timeline-plan">[2]</a>,
                <a href="https://www.alignmentforum.org/posts/K2D45BNxnZjdpSX2j/ai-timelines">[3]</a>) given the current
                rate of progress in AI research and development.

                There are grave consequences in deploying rogue or misaligned AI systems in public, translating to
                monetary losses of millions or billions (See <a
                    href="https://www.calvin-risk.com/blog/decoding-the-monetary-impact">[1]</a>).
            </p>

            <p>
                Despite spectacular progress in building new AI systems (See <a
                    href="https://arcprize.org/blog/oai-o3-pub-breakthrough">[7]</a>), there is a glaring stagnation in
                the research and development of safeguards and safety protocols around these systems. According to an
                80000-hour article, there were only around 300 AI safety researchers in 2022 (See <a
                    href="https://80000hours.org/career-reviews/ai-safety-researcher/#:~:text=We%20estimated%20in%202022%20that,risk%20could%20be%20quite%20challenging.">[5]</a>).

                The number of AI safety researchers has been increasing at about 28% per year (See <a
                    href="https://www.lesswrong.com/posts/mC3oeq62DWeqxiNBx/estimating-the-current-and-future-number-of-ai-safety">[6]</a>).
                Using this growth rate, one estimate suggests that the number of AI safety researchers could have
                increased to around 580 by 2024.

                There has been a rise of 315% in AI safety-related articles between 2017 and 2022 (See <a
                    href="https://almanac.eto.tech/topics/ai-safety/#vital-signs">[4]</a> ). However, it is still a
                "drop in the bucket," with merely 2% of all articles in AI/ML being directly related to safety.
            </p>

            <p>
                <strong>
                    What events have to take place starting today to prevent AGI from becoming a catastrophic risk to
                    humanity and/or to mitigate the loss of monetary and human life in the near and long-term future?
                </strong>
            </p>

            <p>
                We believe that our best shot at mitigating the risks of AGI is to develop safety and control protocols
                on a technical level and devise new policies for containing potential misuse. Given the dearth of AI
                safety researchers and the proven track record of IITians, this is the most opportune time for
                short-term investment to promote technical AI safety as a career option for IITians and to initiate them
                on this path.
            </p>

            <p>
                There are 23 IITs in India, but no AI safety group exists in any of them. The IIT Delhi AI Safety
                Initiative is the first-of-its-kind student research group catering to the bright young minds in
                the Indian subcontinent, modeled around student safety groups at other universities in the West such as
                HAIST <a href="https://haist.ai/">[9]</a>, Oxford AI safety initiative <a
                    href="https://oaisi.org/">[10]</a>, and Berkeley AI safety initiative <a
                    href="https://berkeleyaisafety.com/">[11]</a>.
            </p>
        </section>
    </div>

    <footer>
        <p>&copy; 2025 IIT Delhi AI Safety Initiative. All rights reserved.</p>
    </footer>

    <script>
        // Intersection Observer for scroll animations
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        }, {
            threshold: 0.1
        });

        // Observe all sections
        document.querySelectorAll('section').forEach(section => {
            observer.observe(section);
        });
    </script>
</body>
</html> 